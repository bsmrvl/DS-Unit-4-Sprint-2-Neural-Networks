{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGGrt9EYlCqY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Train Practice\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Using your baseline model from yesterday, hyperparameter tune it and report on your highest validation accuracy. Your singular goal today is to achieve the highest accuracy possible.\n",
    "\n",
    "*Don't forgot to switch to GPU on Colab!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptJ2b3wk62Ud"
   },
   "source": [
    "### Hyperparameters to Tune\n",
    "\n",
    "At a minimum, tune each of these hyperparameters using any strategy we discussed during lecture today: \n",
    "- Optimizer\n",
    "- Learning Rate\n",
    "- Activiation Function\n",
    "  - At least 1 subparameter within the Relu activation function\n",
    "- Number of Neurons in Hidden Layers\n",
    "- Number of Hidden Layers\n",
    "- Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USXjs7Hk71Hy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers as opt\n",
    "from tensorflow.keras import activations as act\n",
    "from tensorflow.keras import initializers as ini\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_quickdraw10(path, test_size=.2, random_state=42):\n",
    "    data = np.load(path)\n",
    "    X = data['arr_0']\n",
    "    y = data['arr_1']\n",
    "    X, y = shuffle(\n",
    "               X, y, \n",
    "               random_state=random_state\n",
    "           )\n",
    "    return train_test_split(\n",
    "               X, y, \n",
    "               test_size=test_size, \n",
    "               random_state=random_state\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../quickdraw10.npz'\n",
    "X_train, X_val, y_train, y_val = load_quickdraw10(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(optimizer=opt.Adam(), activation=act.relu, neurons=64, h_layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(neurons, activation=activation, input_dim=784))\n",
    "    \n",
    "    for i in range(h_layers):\n",
    "        model.add(layers.Dense(neurons, activation=activation))\n",
    "        \n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 1.5145 - accuracy: 0.6556 - val_loss: 0.8051 - val_accuracy: 0.7544\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6858 - accuracy: 0.7902 - val_loss: 0.6786 - val_accuracy: 0.7989\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5966 - accuracy: 0.8165 - val_loss: 0.6412 - val_accuracy: 0.8104\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5485 - accuracy: 0.8305 - val_loss: 0.6008 - val_accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5181 - accuracy: 0.8407 - val_loss: 0.5790 - val_accuracy: 0.8286\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4865 - accuracy: 0.8502 - val_loss: 0.5699 - val_accuracy: 0.8320\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.4659 - accuracy: 0.8564 - val_loss: 0.5591 - val_accuracy: 0.8353\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4455 - accuracy: 0.8634 - val_loss: 0.5642 - val_accuracy: 0.8390\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4275 - accuracy: 0.8679 - val_loss: 0.5520 - val_accuracy: 0.8410\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4084 - accuracy: 0.8745 - val_loss: 0.5500 - val_accuracy: 0.8425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16476eb3550>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = new_model(\n",
    "    h_layers=3,\n",
    "    neurons=80,\n",
    "    optimizer=opt.Nadam()\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3912 - accuracy: 0.8793 - val_loss: 0.5495 - val_accuracy: 0.8448\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3812 - accuracy: 0.8825 - val_loss: 0.5527 - val_accuracy: 0.8451\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3705 - accuracy: 0.8855 - val_loss: 0.5532 - val_accuracy: 0.8459\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3542 - accuracy: 0.8911 - val_loss: 0.5571 - val_accuracy: 0.8436\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3436 - accuracy: 0.8934 - val_loss: 0.5470 - val_accuracy: 0.8492\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3340 - accuracy: 0.8961 - val_loss: 0.5778 - val_accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3262 - accuracy: 0.8992 - val_loss: 0.5909 - val_accuracy: 0.8458\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 0.3187 - accuracy: 0.9018 - val_loss: 0.5823 - val_accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3081 - accuracy: 0.9052 - val_loss: 0.5878 - val_accuracy: 0.8482\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3008 - accuracy: 0.9081 - val_loss: 0.6075 - val_accuracy: 0.8491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16476d9a7c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKbr1gRg9BXs"
   },
   "source": [
    "### Stretch Goals\n",
    "- Implement Bayesian Hyper-parameter Optimization\n",
    "- Select a new dataset and apply a neural network to it.\n",
    "- Use a cloud base experiment tracking framework such as weights and biases\n",
    "- Research potential architecture ideas for this problem. Try Lenet-10 for example. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_433_Tune_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "nteract": {
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
